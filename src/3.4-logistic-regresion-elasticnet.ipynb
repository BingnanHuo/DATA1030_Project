{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compustat World Firms Industry Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file was created to make parallesim easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Import Libraries and Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from scipy.stats import uniform, loguniform\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Preprocessing & Splitting\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, StratifiedGroupKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modeling\n",
    "from skopt import BayesSearchCV \n",
    "import xgboost\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Utils\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "compustat = pd.read_pickle('../data/compustat_ftreng.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748178, 139)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compustat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ftrs = ['fyearq','fqtr']\n",
    "num_ftrs = ['saleq', 'gpq', 'oiadpq', 'oibdpq', 'cogsq',\n",
    "       'xoprq', 'atq', 'seqq', 'dlcq', 'dlttq', 'capxy', 'oancfy', 'gpm',\n",
    "       'opm', 'ocfm', 'roa', 'roe', 'cd_ratio', 'ca_ratio', 'fca_ratio',\n",
    "       'fce_ratio', 'fcd_ratio', 'fcs_ratio', 'tat', 'cr', 'tdr', 'der',\n",
    "       'gpm_lag1', 'gpm_lag2', 'gpm_lag3', 'gpm_lag4', 'opm_lag1',\n",
    "       'opm_lag2', 'opm_lag3', 'opm_lag4', 'ocfm_lag1', 'ocfm_lag2',\n",
    "       'ocfm_lag3', 'ocfm_lag4', 'roa_lag1', 'roa_lag2', 'roa_lag3',\n",
    "       'roa_lag4', 'roe_lag1', 'roe_lag2', 'roe_lag3', 'roe_lag4',\n",
    "       'fca_ratio_lag1', 'fca_ratio_lag2', 'fca_ratio_lag3',\n",
    "       'fca_ratio_lag4', 'fce_ratio_lag1', 'fce_ratio_lag2',\n",
    "       'fce_ratio_lag3', 'fce_ratio_lag4', 'fcd_ratio_lag1',\n",
    "       'fcd_ratio_lag2', 'fcd_ratio_lag3', 'fcd_ratio_lag4',\n",
    "       'fcs_ratio_lag1', 'fcs_ratio_lag2', 'fcs_ratio_lag3',\n",
    "       'fcs_ratio_lag4', 'tat_lag1', 'tat_lag2', 'tat_lag3', 'tat_lag4',\n",
    "       'cr_lag1', 'cr_lag2', 'cr_lag3', 'cr_lag4', 'tdr_lag1', 'tdr_lag2',\n",
    "       'tdr_lag3', 'tdr_lag4', 'der_lag1', 'der_lag2', 'der_lag3',\n",
    "       'der_lag4', 'gpm_mean_4Q', 'gpm_std_4Q', 'gpm_mean_8Q',\n",
    "       'gpm_std_8Q', 'opm_mean_4Q', 'opm_std_4Q', 'opm_mean_8Q',\n",
    "       'opm_std_8Q', 'ocfm_mean_4Q', 'ocfm_std_4Q', 'ocfm_mean_8Q',\n",
    "       'ocfm_std_8Q', 'roa_mean_4Q', 'roa_std_4Q', 'roa_mean_8Q',\n",
    "       'roa_std_8Q', 'roe_mean_4Q', 'roe_std_4Q', 'roe_mean_8Q',\n",
    "       'roe_std_8Q', 'fca_ratio_mean_4Q', 'fca_ratio_std_4Q',\n",
    "       'fca_ratio_mean_8Q', 'fca_ratio_std_8Q', 'fce_ratio_mean_4Q',\n",
    "       'fce_ratio_std_4Q', 'fce_ratio_mean_8Q', 'fce_ratio_std_8Q',\n",
    "       'fcd_ratio_mean_4Q', 'fcd_ratio_std_4Q', 'fcd_ratio_mean_8Q',\n",
    "       'fcd_ratio_std_8Q', 'fcs_ratio_mean_4Q', 'fcs_ratio_std_4Q',\n",
    "       'fcs_ratio_mean_8Q', 'fcs_ratio_std_8Q', 'tat_mean_4Q',\n",
    "       'tat_std_4Q', 'tat_mean_8Q', 'tat_std_8Q', 'cr_mean_4Q',\n",
    "       'cr_std_4Q', 'cr_mean_8Q', 'cr_std_8Q', 'tdr_mean_4Q',\n",
    "       'tdr_std_4Q', 'tdr_mean_8Q', 'tdr_std_8Q', 'der_mean_4Q',\n",
    "       'der_std_4Q', 'der_mean_8Q', 'der_std_8Q']\n",
    "\n",
    "#cat_ftrs = ['loc','curcdq']  # maybe not include country for now\n",
    "cat_ftrs = ['curcdq'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_transformer = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())])\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=True, handle_unknown='ignore'))])\n",
    "preprocessor1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('minmax', minmax_transformer, year_ftrs),\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])\n",
    "\n",
    "numeric_transformer2 = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0))])\n",
    "categorical_transformer2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))])\n",
    "preprocessor2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('minmax', minmax_transformer, year_ftrs),\n",
    "        ('num', numeric_transformer2, num_ftrs),\n",
    "        ('cat', categorical_transformer2, cat_ftrs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessor suitable for XGBoost, will produce missing values\n",
    "\n",
    "Preprocessor2 is for random forest, LR, etc. It will fill missing values with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning w/ RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ML_BayesSearch_CV(X_og, y_og, groups_og, preprocessor, ML_algo, search_space, sample_size=None):\n",
    "    # Loop for 5 random states\n",
    "    # in each loop, split, preprocess, fit, and score\n",
    "    random_states = [377, 575, 610, 777, 233]\n",
    "\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    reports = []\n",
    "    cms = []\n",
    "    best_param = []\n",
    "    best_score = []\n",
    "\n",
    "    for i in range(1):\n",
    "        this_rs = random_states[i]\n",
    "        \n",
    "        # Split into [train,val] and test sets (80%, 20%)\n",
    "        sgss = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=this_rs)\n",
    "        splits = enumerate(sgss.split(X_og, y_og, groups_og))\n",
    "\n",
    "        print('Splitting dataset into train-val and test sets (80%, 20%)')\n",
    "        i, (train_val_idx, test_idx) = next(splits)\n",
    "        X_train_val, X_test = X_og.iloc[train_val_idx], X_og.iloc[test_idx]\n",
    "        y_train_val, y_test = y_og.iloc[train_val_idx], y_og.iloc[test_idx]\n",
    "        group_train_val, group_test = groups_og.iloc[train_val_idx], groups_og.iloc[test_idx]\n",
    "\n",
    "\n",
    "        #full_length = len(y_train_val)\n",
    "        # After getting test set, downsample train-val \n",
    "        if sample_size is None:\n",
    "            pass\n",
    "        elif sample_size <= 0.3*0.8:\n",
    "            print('Sampling dataset for hyperparameter tuning, sample size of train set (80%): ', sample_size*100,'%')\n",
    "            flat_idx = downsample_classes(y_train_val, group_train_val, random_state=this_rs)\n",
    "            flat_X, flat_y, flat_groups = X_train_val.iloc[flat_idx], y_train_val.iloc[flat_idx], group_train_val.iloc[flat_idx]\n",
    "            flat_prop = len(flat_idx)/len(y_train_val)\n",
    "            if int(flat_prop/sample_size)<=1: # no need to do more sampling\n",
    "                X, y = flat_X, flat_y\n",
    "                groups = flat_groups\n",
    "            else:\n",
    "                sampler = StratifiedGroupKFold(n_splits=int(flat_prop/sample_size), shuffle=True, random_state=this_rs)\n",
    "                splits = enumerate(sampler.split(flat_X, flat_y, flat_groups))\n",
    "                i, (_, sampled_idx) = next(splits)\n",
    "                X, y = flat_X.iloc[sampled_idx], flat_y.iloc[sampled_idx]\n",
    "                groups = flat_groups.iloc[sampled_idx]\n",
    "        else:\n",
    "            pass\n",
    "        X_train_val, y_train_val, group_train_val = X, y, groups\n",
    "                \n",
    "\n",
    "        # Split [train,val] into train and val sets (64%, 16%)\n",
    "        sgss_cv = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=this_rs)\n",
    "        pipe = make_pipeline(preprocessor, \n",
    "                             PCA(n_components=0.95, random_state=this_rs),\n",
    "                             ML_algo)\n",
    "        print('Random State Loop: ', i+1)\n",
    "        print('Random State: ', this_rs)\n",
    "        print('***Start Bayes Search***')\n",
    "\n",
    "        bayes_search = BayesSearchCV(estimator=pipe,\n",
    "                                    search_spaces=search_space,\n",
    "                                    n_iter=20,  # Number of iterations\n",
    "                                    cv=sgss_cv,       # Cross-validation strategy\n",
    "                                    n_jobs=-1,  # Use all available cores\n",
    "                                    scoring='f1_weighted',\n",
    "                                    verbose=1,\n",
    "                                    random_state=this_rs)\n",
    "\n",
    "\n",
    "        bayes_search.fit(X_train_val, y_train_val, groups=group_train_val)        \n",
    "    \n",
    "        # Make predictions and calculate accuracy on the test set\n",
    "        y_pred = bayes_search.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(*vote_pred(y_test, y_pred, group_test))\n",
    "        precision = precision_score(*vote_pred(y_test, y_pred, group_test), average=\"weighted\")\n",
    "        recall = recall_score(*vote_pred(y_test, y_pred, group_test), average=\"weighted\")\n",
    "        f1 = f1_score(*vote_pred(y_test, y_pred, group_test), average=\"weighted\")\n",
    "\n",
    "        report = classification_report(*vote_pred(y_test, y_pred, group_test))\n",
    "        cm = confusion_matrix(*vote_pred(y_test, y_pred, group_test))\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        reports.append(report)\n",
    "        cms.append(cm)\n",
    "        best_param.append(bayes_search.best_params_)\n",
    "        best_score.append(bayes_search.best_score_)\n",
    "        \n",
    "    return accuracy_scores, precision_scores, recall_scores, f1_scores, cms, best_param, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2748178, 135)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compustat[cat_ftrs] = compustat[cat_ftrs].astype(str)\n",
    "\n",
    "groups = compustat['gvkey']\n",
    "y = compustat['gsector_num']\n",
    "X = compustat.drop(['gvkey','gsector','gsector_num','datafqtr'], axis=1)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (Multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into train-val and test sets (80%, 20%)\n",
      "Sampling dataset for hyperparameter tuning, sample size of train set (80%):  1.0 %\n",
      "Random State Loop:  1\n",
      "Random State:  377\n",
      "***Start Bayes Search***\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/data1030/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "search_space_lr = {\n",
    "    'logisticregression__C': Real(1e-4, 1e+4, 'log-uniform'),\n",
    "    'logisticregression__l1_ratio': Real(0, 1, 'uniform'),\n",
    "    'logisticregression__solver': Categorical(['saga']),\n",
    "    'logisticregression__max_iter': Integer(5000, 10000)  \n",
    "}\n",
    "\n",
    "lr_clf = LogisticRegression(multi_class='multinomial', penalty='elasticnet')\n",
    "acc_lr, pre_lr, rec_lr, f1_lr, \\\n",
    "    cm_lr, params_lr, bs_lr = ML_BayesSearch_CV(X, y, groups, preprocessor2, \n",
    "                                                lr_clf, search_space_lr, sample_size=0.01)\n",
    "    \n",
    "lr_results = {\n",
    "    \"accuracy\": acc_lr,\n",
    "    \"precision\": pre_lr,\n",
    "    \"recall\": rec_lr,\n",
    "    \"f1_score\": f1_lr,\n",
    "    \"conf_matrix\": cm_lr,\n",
    "    \"params\": params_lr,\n",
    "    \"best_score\": bs_lr\n",
    "}\n",
    "with open('../results/lr_results.pkl', 'wb') as file:\n",
    "    pickle.dump(lr_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.23084754390430134],\n",
       " 'precision': [0.2819775283008166],\n",
       " 'recall': [0.23084754390430134],\n",
       " 'f1_score': [0.2119857138324001],\n",
       " 'conf_matrix': [array([[174,  55,   5, 155,   1,  37,  20,  26,  43, 126,  33],\n",
       "         [ 83, 260,  41, 496,   8,  94,  30,  81, 107, 240,  58],\n",
       "         [ 81,  64,  88, 942,  28,  34, 125, 182, 183, 322,  99],\n",
       "         [ 61,  66,  58, 777,  24,  16,  75, 233, 204, 174,  99],\n",
       "         [ 27,  23,  26, 375,   9,  12,  31,  95,  91,  85,  31],\n",
       "         [ 40, 131,  13, 226,   2, 143,  39, 286, 216,  63,  95],\n",
       "         [ 11,  13,   7,  96,   5,   5, 390,  29,  47,  26, 116],\n",
       "         [ 53,  75,  34, 606,  13,  52, 111, 524, 245, 121,  43],\n",
       "         [ 35,  21,   8, 126,   7,  24,  33,  86, 110,  67,  28],\n",
       "         [ 23,   3,   5,  43,   0,   1,  14,  10,  12, 159,  27],\n",
       "         [ 10,   1,   3,  21,   0,   4,   9,   1,   3,  17,  87]])],\n",
       " 'params': [OrderedDict([('logisticregression__C', 0.014502448000246788),\n",
       "               ('logisticregression__l1_ratio', 0.0),\n",
       "               ('logisticregression__max_iter', 9553),\n",
       "               ('logisticregression__solver', 'saga')])],\n",
       " 'best_score': [0.21308423800652648]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.3076923076923077, 0.0],\n",
       " 'precision': [0.3541669868592946, 0.0],\n",
       " 'recall': [0.3076923076923077, 0.0],\n",
       " 'f1_score': [0.3007782873226413, 0.0],\n",
       " 'conf_matrix': [array([[6, 1, 1, 0, 2, 1, 0, 0, 2, 4, 1],\n",
       "         [3, 2, 1, 0, 0, 2, 1, 1, 2, 0, 1],\n",
       "         [0, 4, 1, 0, 2, 0, 0, 2, 0, 2, 1],\n",
       "         [0, 2, 0, 1, 0, 0, 0, 2, 2, 0, 1],\n",
       "         [0, 3, 2, 0, 1, 0, 0, 1, 3, 3, 3],\n",
       "         [0, 0, 0, 0, 0, 4, 0, 1, 2, 2, 0],\n",
       "         [0, 1, 1, 0, 0, 2, 8, 0, 0, 0, 0],\n",
       "         [1, 3, 2, 0, 1, 6, 1, 6, 2, 0, 1],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 1],\n",
       "         [1, 3, 0, 0, 1, 0, 1, 0, 0, 8, 1],\n",
       "         [1, 0, 0, 0, 0, 0, 2, 0, 0, 2, 6]]),\n",
       "  array([[0, 0],\n",
       "         [1, 0]])],\n",
       " 'params': [OrderedDict([('logisticregression__C', 0.038024176463958406),\n",
       "               ('logisticregression__l1_ratio', 0.0),\n",
       "               ('logisticregression__max_iter', 10000),\n",
       "               ('logisticregression__solver', 'saga')]),\n",
       "  OrderedDict([('logisticregression__C', 374.41497379557813),\n",
       "               ('logisticregression__l1_ratio', 0.48594683015829865),\n",
       "               ('logisticregression__max_iter', 5432),\n",
       "               ('logisticregression__solver', 'saga')])],\n",
       " 'best_score': [0.2789020490258399, 0.0]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results = pickle.load(open('../results/lr_results.pkl', 'rb'))\n",
    "lr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
